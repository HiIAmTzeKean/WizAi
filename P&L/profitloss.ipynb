{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Tuple, Dict, List\n",
    "from collections import namedtuple\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"all.xlsx\"\n",
    "df = pd.read_excel(io=filename)\n",
    "\n",
    "# Update header\n",
    "df.columns = df.iloc[3]\n",
    "holding_entity = Entity=df.iloc[0,0]\n",
    "\n",
    "# Drop first 3 rows as it contains file meta\n",
    "df = df.drop(index=[0,1,2,3])\n",
    "df[\"Client name\"] = \"\"\n",
    "\n",
    "# Create entity column\n",
    "# df = df.assign(Entity=holding_entity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>3</th>\n",
       "      <th>Date</th>\n",
       "      <th>Source</th>\n",
       "      <th>Contact</th>\n",
       "      <th>Description</th>\n",
       "      <th>Reference</th>\n",
       "      <th>Currency</th>\n",
       "      <th>Debit (Source)</th>\n",
       "      <th>Credit (Source)</th>\n",
       "      <th>Debit (SGD)</th>\n",
       "      <th>Credit (SGD)</th>\n",
       "      <th>Account</th>\n",
       "      <th>Client name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-03 00:00:00</td>\n",
       "      <td>Receivable Invoice</td>\n",
       "      <td>STELLAR AI HOLDINGS PTE LTD</td>\n",
       "      <td>STELLAR AI HOLDINGS PTE LTD - Subscription fee...</td>\n",
       "      <td>083-15-R2</td>\n",
       "      <td>SGD</td>\n",
       "      <td>0</td>\n",
       "      <td>4400</td>\n",
       "      <td>0</td>\n",
       "      <td>4400</td>\n",
       "      <td>Sales - Subscription Fees</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-01-06 00:00:00</td>\n",
       "      <td>Receivable Invoice</td>\n",
       "      <td>Mitou Hong Kong Limited</td>\n",
       "      <td>Mitou Hong Kong Limited - Usage-based charges ...</td>\n",
       "      <td>173-1</td>\n",
       "      <td>USD</td>\n",
       "      <td>0</td>\n",
       "      <td>1432.73</td>\n",
       "      <td>0</td>\n",
       "      <td>1929.31</td>\n",
       "      <td>Sales - Usage Fees</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "3                 Date              Source                      Contact   \n",
       "4  2023-01-03 00:00:00  Receivable Invoice  STELLAR AI HOLDINGS PTE LTD  \\\n",
       "5  2023-01-06 00:00:00  Receivable Invoice      Mitou Hong Kong Limited   \n",
       "\n",
       "3                                        Description  Reference Currency   \n",
       "4  STELLAR AI HOLDINGS PTE LTD - Subscription fee...  083-15-R2      SGD  \\\n",
       "5  Mitou Hong Kong Limited - Usage-based charges ...      173-1      USD   \n",
       "\n",
       "3 Debit (Source) Credit (Source) Debit (SGD) Credit (SGD)   \n",
       "4              0            4400           0         4400  \\\n",
       "5              0         1432.73           0      1929.31   \n",
       "\n",
       "3                    Account Client name  \n",
       "4  Sales - Subscription Fees              \n",
       "5         Sales - Usage Fees              "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class profit_and_loss():\n",
    "    def __init__(self) -> None:\n",
    "        self.client_file: str = \"client.xlsx\"\n",
    "        self.profit_loss_file: str = \"all.xlsx\"\n",
    "        self.create_client_mapping()\n",
    "        self.pl_df = self.get_profit_loss_df()\n",
    "        \n",
    "    def get_profit_loss_df(self) -> pd.DataFrame:\n",
    "        df = pd.read_excel(io=filename)\n",
    "\n",
    "        # Update header\n",
    "        df.columns = df.iloc[3]\n",
    "        holding_entity = Entity=df.iloc[0,0]\n",
    "\n",
    "        # Drop first 3 rows as it contains file meta\n",
    "        df = df.drop(index=[0,1,2,3])\n",
    "        df[\"Client name\"] = \"\"\n",
    "        df = df.assign(Entity=holding_entity)\n",
    "        return df\n",
    "    \n",
    "    def create_client_mapping(self) -> None:\n",
    "        \"\"\"Creates variables as helper for mapping\n",
    "        \"\"\"\n",
    "        # Read excel file\n",
    "        df = pd.read_excel(io=self.client_file,header=0)\n",
    "        # Cleam file\n",
    "        df[\"Client Code\"] = pd.to_numeric(df[\"Client Code\"], errors='coerce').fillna(0).astype(int)\n",
    "        df[\"Xero Entity Name\"] = df[\"Xero Entity Name\"].fillna(\"TBC\")\n",
    "\n",
    "        # create auxilary lists\n",
    "        churn_df = df.loc[(df[\"Xero Entity Name\"] == \"CHURNED\" )].drop(columns=[\"Xero Entity Name\"])\n",
    "        tbc_df = df.loc[(df[\"Xero Entity Name\"] == \"TBC\" )].drop(columns=[\"Xero Entity Name\"])\n",
    "        self.churn_dict: Dict[str,dict] = churn_df.set_index(\"Client Name\").T.to_dict()\n",
    "        self.tbc_dict: Dict[str,dict] = tbc_df.set_index(\"Client Name\").T.to_dict()\n",
    "\n",
    "        # create clean dict\n",
    "        clean_df = df.loc[(df[\"Xero Entity Name\"] != \"TBC\" ) & (df[\"Xero Entity Name\"] != \"CHURNED\" )]\n",
    "        self.entity_key_dict: Dict[str,List] = clean_df.set_index(\"Xero Entity Name\").T.to_dict('list')\n",
    "        self.code_key_dict: Dict[str,List]= clean_df.set_index(\"Client Code\").T.to_dict('list')\n",
    "    \n",
    "    def find_client_name_by_entity_name(self, entity_name:str) -> str|None:\n",
    "        \"\"\"Returns client name by searching using entity name\n",
    "\n",
    "        Args:\n",
    "            entity_name (str): _description_\n",
    "\n",
    "        Returns:\n",
    "            str: _description_\n",
    "        \"\"\"\n",
    "        record: str = self.entity_key_dict.get(entity_name,None)\n",
    "        if record == None:\n",
    "            return None\n",
    "        return record[0]\n",
    "            \n",
    "    def find_client_name_by_code(self, customer_code:str) -> str|None:\n",
    "        \"\"\"Returns client name by searching using customer code\n",
    "\n",
    "        Args:\n",
    "            customer_code (str): _description_\n",
    "\n",
    "        Returns:\n",
    "            str: _description_\n",
    "        \"\"\"\n",
    "        record: str = self.code_key_dict.get(customer_code,None)\n",
    "        if record == None:\n",
    "            return None\n",
    "        return record[0]\n",
    "\n",
    "    def force_find_client_name(self, description_field:str) -> str:\n",
    "        \"\"\"Brute force search client name in description field.\n",
    "        Try each index in clean list, then CHURNED\n",
    "\n",
    "        Returns:\n",
    "            str: _description_\n",
    "        \"\"\"\n",
    "        # Test each entity name in the dict\n",
    "        for key in self.entity_key_dict:\n",
    "            if key in description_field:\n",
    "                # key subset of description\n",
    "                # return client name from list\n",
    "                return self.entity_key_dict[0]\n",
    "        # Test all churned item\n",
    "        for key in self.churn_dict:\n",
    "            if key in description_field:\n",
    "                # key subset of description\n",
    "                return key\n",
    "        return \"\"\n",
    "\n",
    "    def populate_client_name(self) -> pd.DataFrame:\n",
    "        # for each row in dataframe\n",
    "        for index, row in self.pl_df.iterrows():\n",
    "            found:bool = False\n",
    "            # if there exist a contact\n",
    "            if not pd.isnull(row[\"Contact\"]):\n",
    "                client_name = self.find_client_name_by_entity_name(row[\"Contact\"])\n",
    "                if client_name:\n",
    "                    row[\"Client name\"] = client_name\n",
    "                    continue\n",
    "\n",
    "            # if there exist a reference number\n",
    "            if not pd.isnull(row[\"Reference\"]):\n",
    "                # get the first number\n",
    "                customer_code:str = row[\"Reference\"].split(\"-\")[0]\n",
    "                # check number against the client list\n",
    "                client_name = self.find_client_name_by_code(customer_code)\n",
    "                if client_name:\n",
    "                    row[\"Client name\"] = client_name\n",
    "                    continue\n",
    "                \n",
    "            # if all fails\n",
    "            # then for each valid xero entity name\n",
    "            # check if it exists within the description\n",
    "            # if true, then update the client field as such\n",
    "            row[\"Client name\"] = self.force_find_client_name(row[\"Description\"])\n",
    "        \n",
    "\n",
    "    def save_to_csv(self, filename) -> None:\n",
    "        np.savetxt(\"compiled.csv\", \n",
    "           self.pl_df,\n",
    "           delimiter =\",\", \n",
    "           fmt ='%s')\n",
    "    \n",
    "    def start(self) -> None:\n",
    "        # update dataframe\n",
    "        self.populate_client_name()\n",
    "        self.save_to_csv(\"compiled.csv\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngtze\\AppData\\Local\\Temp\\ipykernel_27068\\1107422264.py:17: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  entity_key_dict = clean_df.set_index(\"Xero Entity Name\").T.to_dict('list')\n",
      "C:\\Users\\ngtze\\AppData\\Local\\Temp\\ipykernel_27068\\1107422264.py:18: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  code_key_dict = clean_df.set_index(\"Client Code\").T.to_dict('list')\n"
     ]
    }
   ],
   "source": [
    "filename = \"client.xlsx\"\n",
    "\n",
    "# Read excel file\n",
    "df = pd.read_excel(io=filename,header=0)\n",
    "# Cleam file\n",
    "df[\"Client Code\"] = pd.to_numeric(df[\"Client Code\"], errors='coerce').fillna(0).astype(int)\n",
    "df[\"Xero Entity Name\"] = df[\"Xero Entity Name\"].fillna(\"TBC\")\n",
    "\n",
    "# create auxilary lists\n",
    "churn_df = df.loc[(df[\"Xero Entity Name\"] == \"CHURNED\" )].drop(columns=[\"Xero Entity Name\"])\n",
    "tbc_df = df.loc[(df[\"Xero Entity Name\"] == \"TBC\" )].drop(columns=[\"Xero Entity Name\"])\n",
    "churn_list = churn_df.values.tolist()\n",
    "tbc_list = tbc_df.values.tolist()\n",
    "\n",
    "# create clean dict\n",
    "clean_df = df.loc[(df[\"Xero Entity Name\"] != \"TBC\" ) & (df[\"Xero Entity Name\"] != \"CHURNED\" )]\n",
    "entity_key_dict = clean_df.set_index(\"Xero Entity Name\").T.to_dict('list')\n",
    "code_key_dict = clean_df.set_index(\"Client Code\").T.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngtze\\AppData\\Local\\Temp\\ipykernel_27068\\1006861130.py:38: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  self.entity_key_dict: Dict[str,List] = clean_df.set_index(\"Xero Entity Name\").T.to_dict('list')\n",
      "C:\\Users\\ngtze\\AppData\\Local\\Temp\\ipykernel_27068\\1006861130.py:39: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  self.code_key_dict: Dict[str,List]= clean_df.set_index(\"Client Code\").T.to_dict('list')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Contact'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\ngtze\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\ngtze\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\ngtze\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Contact'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[142], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m t \u001b[39m=\u001b[39m profit_and_loss()\n\u001b[1;32m----> 2\u001b[0m t\u001b[39m.\u001b[39;49mstart()\n",
      "Cell \u001b[1;32mIn[141], line 125\u001b[0m, in \u001b[0;36mprofit_and_loss.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstart\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[39m# update dataframe\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpopulate_client_name()\n\u001b[0;32m    126\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msave_to_csv(\u001b[39m\"\u001b[39m\u001b[39mcompiled.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[141], line 94\u001b[0m, in \u001b[0;36mprofit_and_loss.populate_client_name\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m found:\u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[39m# if there exist a contact\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m pd\u001b[39m.\u001b[39misnull(row[\u001b[39m\"\u001b[39;49m\u001b[39mContact\u001b[39;49m\u001b[39m\"\u001b[39;49m]):\n\u001b[0;32m     95\u001b[0m     client_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfind_client_name_by_entity_name(row[\u001b[39m\"\u001b[39m\u001b[39mContact\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m     96\u001b[0m     \u001b[39mif\u001b[39;00m client_name:\n",
      "File \u001b[1;32mc:\\Users\\ngtze\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1004\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m   1006\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1007\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m   1009\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m   1010\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1012\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ngtze\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1115\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1116\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1118\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\ngtze\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Contact'"
     ]
    }
   ],
   "source": [
    "t = profit_and_loss()\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Carro SG': [7], 'Koinworks': [11], 'Grosiraja': [12], 'Speeddoc': [13], 'Medify Air': [14], 'Double Dragon': [16], 'Ms. Maricela Corpuz': [17], 'Manulife (Aspire Alliance)': [21], 'Wynnes Financial Advisors': [22], 'Redtone': [23], 'Mr Bayani Quilala V': [24], 'Grace Cornejo (Sunlife)': [27], 'Klickair': [28], 'Lifepal': [29], 'Mr. MARTI GIMENEZ (Prudential PH)': [31], 'Ms. Maria Racimo': [32], 'Ms. Hazren Vargas (AXA)': [33], 'Ms. Ginelle Sequitin (Sunlife)': [34], 'Mr. Collin Krishia Templo': [36], 'Mr. Ernest Villela': [37], 'Kudotek (Tekcash)': [39], 'Edelyn Yu (Sunlife)': [40], 'Akseleran': [41], 'Nelson Sequitin': [42], 'Rochelle Visda (Traiblazer)': [43], 'Leslie Abrenica (Maxicare)': [44], 'Jhoanna Marie E. Vorstenbosch (Sunlife)': [45], 'Nina Manipon (Manulife)': [46], 'Mr. Jeffrey Abergos (Manulife)': [47], 'Ms. Leony Escosia (Prudential)': [48], 'Pondo Peso': [49], 'Mr. Carlos Cervantes': [50], 'Timothy Francis Lim': [51], 'Rhea Adlay (Pacific Cross)': [52], 'Jenny Acob': [53], 'Meredith Torres (Sunlife)': [54], 'Marujita P. Trinidad (Sunlife)': [55], 'Tokiomarine Asia Regional': [58], 'Catherine Ortiz (Sunlife)': [59], 'GLOSERINE ANDIN (Sunlife)': [60], 'Jessica Chan (Sunlife)': [61], 'Sarah Saavedra (Inspira Life)': [62], 'Stephanie Abrantes (Sunlife)': [63], 'Jhunnel Sarajan (Alveo)': [64], 'Myrna Solimen (Prulife UK)': [65], 'Mitzi Philline (Prulife UK)': [66], 'Ms. Leila Marie Pagna (Sunlife)': [67], 'Cherry Maniquiz': [68], 'Carlo Canares': [69], 'Angie Verdadero': [70], 'Angel Jarin (Sunlife)': [71], 'Keenu Rem Tafalla (AXA)': [72], 'Shineth Nogar (Sunlife)': [73], 'Paul Jenser Banayo (Sunlife)': [74], 'Kurt Sta. Maria (Prulife UK)': [75], 'Maria Pilones (Sunlife Canada)': [76], 'Cyrelle Ridad (Sunlife)': [77], 'Dave Patrick Sanez (AXA)': [78], 'Carlo Dimayuga (Manulife)': [79], 'Gemma De San Jose (Sunlife)': [80], 'Ces Mejia (Sunlife)': [84], 'Albert Ramir Libre (Sunlife)': [85], 'Denver Corpuz (SMDC)': [90], 'Stephen Sungkip (Sunlife Canada)': [91], 'Jeramie Calma (Prulife UK)': [92], 'Gabino Cunada (Sunlife)': [93], 'Victor De Jesus (Sunlife)': [95], 'Sofia Relosa (AXA)': [97], 'Jake Simeon (Manulife)': [98], 'Cecilia Guazon (Sunlife)': [99], 'Anna Melissa Comendador (Prulife UK)': [100], 'Lisette Aguila (Sunlife)': [101], 'Teresita Rombaoa (Pru Life UK)': [104], 'Paterno Abellera (Sunlife)': [107], 'Rosario Adnin (Sunlife)': [109], 'Gigi Azarcon (Sunlife)': [110], 'Jon Oliquino (AXA PH)': [116], 'Melissa Villareal (Sunlife)': [121], 'Jerimae Acosta': [124], 'Rommel Calague': [127], 'Youbeauty': [137], 'Saku88': [158]}\n"
     ]
    }
   ],
   "source": [
    "d = churn_df.set_index(\"Client Name\").T.to_dict('list')\n",
    "print(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
